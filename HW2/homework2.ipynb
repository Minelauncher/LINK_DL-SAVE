{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e83417",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd5087",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "id": "4d495b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch, random; torch.manual_seed(42); random.seed(42) # 시드 고정\n",
    "\n",
    "# 출력 폭 제한을 해제 (무제한)\n",
    "pd.set_option(\"display.width\", None)\n",
    "# 모든 컬럼 출력되도록 설정\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c05e7",
   "metadata": {},
   "source": [
    "def get_base_dir():는 주피터 노트북 환경에서는 Path(__file__).resolve().parent이 존재하지 않기 때문에 동일한 Path.cwd() 으로 대체하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85dc09",
   "metadata": {},
   "source": [
    "sys.path.append(BASE_PATH) 은 코드가 살펴보는 라이브러리 경로에 임의 경로를 추가하여 임포트를 편리하게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "6546abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# path 초기화 (아마도)\n",
    "sys.path = [(p if isinstance(p, str) else os.fspath(p))\n",
    "            for p in sys.path\n",
    "            if isinstance(p, str) or hasattr(p, \"__fspath__\")]\n",
    "\n",
    "def get_base_dir():\n",
    "    try:\n",
    "        return Path(__file__).resolve().parent  # .py 스크립트/모듈일 때\n",
    "    except NameError:\n",
    "        return Path.cwd()                       # 노트북/인터랙티브일 때\n",
    "    \n",
    "BASE_PATH = get_base_dir().parent # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _01_code._99_common_utils.early_stopping import EarlyStopping # Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2cb3a",
   "metadata": {},
   "source": [
    "Dataset을 상속하는 커스텀 데이터셋 클래스에는 __len__()와 __getitem__(1)가 필수로 들어간다.\n",
    "이것을 오버로딩해줘야 데이터셋을 로드하거나 스플릿 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "id": "778f48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.X = torch.FloatTensor(X)\n",
    "    self.y = torch.LongTensor(y)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx]\n",
    "    target = self.y[idx]\n",
    "    return {'input': feature, 'target': target}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "      len(self.X), self.X.shape, self.y.shape\n",
    "    )\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "068ec1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "  def __init__(self, X):\n",
    "    self.X = torch.FloatTensor(X)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    feature = self.X[idx]\n",
    "    return {'input': feature}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "      len(self.X), self.X.shape\n",
    "    )\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8c80c",
   "metadata": {},
   "source": [
    "get_preprocessed_dataset_N 함수들은 라이브러리 기능을 활용하여 데이터셋 전처리를 하는 부분이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "a5d5847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_1(all_df):\n",
    "    # Pclass별 Fare (요금) 평균값을 사용하여 Fare 결측치 메우기\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "    all_df = all_df.drop(columns=[\"Fare_mean\"])\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "dbc68fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_2(all_df):\n",
    "    # name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    name_df.columns = [\"family_name\", \"title\", \"name\"]\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"title\"] = name_df[\"title\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "813963e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_3(all_df):\n",
    "    # title별 Age 평균값을 사용하여 Age 결측치 메우기\n",
    "    title_age_mean = all_df[[\"title\", \"Age\"]].groupby(\"title\").median().round().reset_index()\n",
    "    title_age_mean.columns = [\"title\", \"title_age_mean\", ]\n",
    "    all_df = pd.merge(all_df, title_age_mean, on=\"title\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"title_age_mean\"]\n",
    "    all_df = all_df.drop([\"title_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "6b6e9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # 가족수(family_num) 컬럼 새롭게 추가\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "\n",
    "    # 혼자탑승(alone) 컬럼 새롭게 추가\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "\n",
    "    #all_df[\"alone\"].fillna(0, inplace=True) # 경고 때문에 고침\n",
    "    all_df[\"alone\"]    = all_df[\"alone\"].fillna(0)\n",
    "\n",
    "    # 학습에 불필요한 컬럼 제거\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "bb98f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_5(all_df):\n",
    "    # title 값 개수 줄이기\n",
    "    all_df.loc[\n",
    "    ~(\n",
    "            (all_df[\"title\"] == \"Mr\") |\n",
    "            (all_df[\"title\"] == \"Miss\") |\n",
    "            (all_df[\"title\"] == \"Mrs\") |\n",
    "            (all_df[\"title\"] == \"Master\")\n",
    "    ),\n",
    "    \"title\"\n",
    "    ] = \"other\"\n",
    "    #all_df[\"Embarked\"].fillna(\"missing\", inplace=True) # 경고 때문에 고침\n",
    "    all_df[\"Embarked\"] = all_df[\"Embarked\"].fillna(\"missing\")\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "id": "1a30a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_6(all_df):\n",
    "    # 카테고리 변수를 LabelEncoder를 사용하여 수치값으로 변경하기\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        le = LabelEncoder()\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "          le = le.fit(all_df[category_feature])\n",
    "          all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b40e44",
   "metadata": {},
   "source": [
    "pd.read_csv() 함수로 경로에 있는 csv를 읽어 판다스 형태로 읽어오고 전처리한 판다스 형태의 자료를 학습용, 검증용, 시험용으로 나눠 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "id": "76116591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset():\n",
    "    #CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "    CURRENT_FILE_PATH = get_base_dir()\n",
    "\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    print(all_df.columns)\n",
    "    print(all_df.head(10))\n",
    "\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    train_y = train_df[\"Survived\"]\n",
    "\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    print(dataset)\n",
    "\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    #print(test_dataset)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17862fff",
   "metadata": {},
   "source": [
    "전처리 확인용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "id": "05c063b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "train_dataset: 713, validation_dataset.shape: 178, test_dataset: 418\n",
      "################################################## 1\n",
      "[TRAIN]\n",
      "0 - torch.Size([16, 10]): torch.Size([16])\n",
      "1 - torch.Size([16, 10]): torch.Size([16])\n",
      "2 - torch.Size([16, 10]): torch.Size([16])\n",
      "3 - torch.Size([16, 10]): torch.Size([16])\n",
      "4 - torch.Size([16, 10]): torch.Size([16])\n",
      "5 - torch.Size([16, 10]): torch.Size([16])\n",
      "6 - torch.Size([16, 10]): torch.Size([16])\n",
      "7 - torch.Size([16, 10]): torch.Size([16])\n",
      "8 - torch.Size([16, 10]): torch.Size([16])\n",
      "9 - torch.Size([16, 10]): torch.Size([16])\n",
      "10 - torch.Size([16, 10]): torch.Size([16])\n",
      "11 - torch.Size([16, 10]): torch.Size([16])\n",
      "12 - torch.Size([16, 10]): torch.Size([16])\n",
      "13 - torch.Size([16, 10]): torch.Size([16])\n",
      "14 - torch.Size([16, 10]): torch.Size([16])\n",
      "15 - torch.Size([16, 10]): torch.Size([16])\n",
      "16 - torch.Size([16, 10]): torch.Size([16])\n",
      "17 - torch.Size([16, 10]): torch.Size([16])\n",
      "18 - torch.Size([16, 10]): torch.Size([16])\n",
      "19 - torch.Size([16, 10]): torch.Size([16])\n",
      "20 - torch.Size([16, 10]): torch.Size([16])\n",
      "21 - torch.Size([16, 10]): torch.Size([16])\n",
      "22 - torch.Size([16, 10]): torch.Size([16])\n",
      "23 - torch.Size([16, 10]): torch.Size([16])\n",
      "24 - torch.Size([16, 10]): torch.Size([16])\n",
      "25 - torch.Size([16, 10]): torch.Size([16])\n",
      "26 - torch.Size([16, 10]): torch.Size([16])\n",
      "27 - torch.Size([16, 10]): torch.Size([16])\n",
      "28 - torch.Size([16, 10]): torch.Size([16])\n",
      "29 - torch.Size([16, 10]): torch.Size([16])\n",
      "30 - torch.Size([16, 10]): torch.Size([16])\n",
      "31 - torch.Size([16, 10]): torch.Size([16])\n",
      "32 - torch.Size([16, 10]): torch.Size([16])\n",
      "33 - torch.Size([16, 10]): torch.Size([16])\n",
      "34 - torch.Size([16, 10]): torch.Size([16])\n",
      "35 - torch.Size([16, 10]): torch.Size([16])\n",
      "36 - torch.Size([16, 10]): torch.Size([16])\n",
      "37 - torch.Size([16, 10]): torch.Size([16])\n",
      "38 - torch.Size([16, 10]): torch.Size([16])\n",
      "39 - torch.Size([16, 10]): torch.Size([16])\n",
      "40 - torch.Size([16, 10]): torch.Size([16])\n",
      "41 - torch.Size([16, 10]): torch.Size([16])\n",
      "42 - torch.Size([16, 10]): torch.Size([16])\n",
      "43 - torch.Size([16, 10]): torch.Size([16])\n",
      "44 - torch.Size([9, 10]): torch.Size([9])\n",
      "[VALIDATION]\n",
      "0 - torch.Size([178, 10]): torch.Size([178])\n",
      "[TEST]\n",
      "0 - torch.Size([418, 10])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "  print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "    len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "  ))\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset), shuffle=True)\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  print(\"[TRAIN]\")\n",
    "  for idx, batch in enumerate(train_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"[VALIDATION]\")\n",
    "  for idx, batch in enumerate(validation_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"[TEST]\")\n",
    "  for idx, batch in enumerate(test_data_loader):\n",
    "    print(\"{0} - {1}\".format(idx, batch['input'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafd330",
   "metadata": {},
   "source": [
    "## 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "id": "8754e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "CURRENT_FILE_PATH = os.path.dirname(get_base_dir())\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "  os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "72894e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "  print(len(train_dataset), len(validation_dataset))\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset), shuffle=True)\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  return train_data_loader, validation_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee1758",
   "metadata": {},
   "source": [
    "FCN을 활용한 모델을 만든다. nn.Module을 상속받고 super().__init__()으로 상속받은 클래스의 생성자를 실행시킨다.\n",
    "nn.Sequential을 사용하여 연속적인 레이어를 쌓는다. forward 함수를 오버로딩해주어야 순전파를 시행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "id": "b705ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "      nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a682047",
   "metadata": {},
   "source": [
    "optim.SGD 으로 파라미터들의 역전파시 어떤 방식(옵티마이저)으로 경사하강법을 시행할 것인지 설정한다. 여기서는 확률적 경사 하강법을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "id": "9df29c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=10, n_output=1)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "id": "77a23231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.BCELoss()\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  early_stopping = EarlyStopping(\n",
    "    patience=wandb.config.early_stop_patience,\n",
    "    delta=wandb.config.early_stop_delta,\n",
    "    project_name=\"\",\n",
    "    checkpoint_file_path=CHECKPOINT_FILE_PATH,\n",
    "    run_time_str=datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "  )\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input, target = train_batch[\"input\"].float(), train_batch[\"target\"].float()\n",
    "      if target.ndim == 1:              # ← 추가\n",
    "        target = target.unsqueeze(1)       # ← 추가\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input, target = validation_batch[\"input\"].float(), validation_batch[\"target\"].float()\n",
    "        if target.ndim == 1:              # ← 추가\n",
    "          target = target.unsqueeze(1)       # ← 추가\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "\n",
    "    if epoch > n_epochs*0.05:\n",
    "      message, early_stop = early_stopping.check_and_save(validation_loss, model)\n",
    "    else:\n",
    "      message, early_stop = \"\", False\n",
    "\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": loss_train / num_trains,\n",
    "      \"Validation loss\": loss_validation / num_validations\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "        f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "        f\"{message} | \"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "    \n",
    "    #if early_stop:\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "id": "747a23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_hidden_unit_list': [20, 20],\n",
    "    'early_stop_patience': 100,\n",
    "    'early_stop_delta': 0,\n",
    "    'validation_intervals': 100,\n",
    "  }\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=\"my_model_training\",\n",
    "    notes=\"My first wandb experiment\",\n",
    "    tags=[\"my_model\", \"homework2\"],\n",
    "    name=current_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader = get_data()\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish()\n",
    "\n",
    "  # --- test dataset 준비\n",
    "  _, _, test_dataset = get_preprocessed_dataset()\n",
    "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  # --- 예측\n",
    "  with torch.no_grad():\n",
    "      for batch in test_loader:\n",
    "          inputs = batch['input']\n",
    "          outputs = linear_model(inputs)\n",
    "          preds = (outputs >= 0.5).int()\n",
    "          preds = preds.ravel().int()\n",
    "\n",
    "  # --- submission.csv 파일로 저장\n",
    "  submission = pd.DataFrame({\n",
    "      'PassengerId': range(892, 892 + len(preds)),  # Kaggle Titanic 기준 test.csv ID 시작 892\n",
    "      'Survived': preds\n",
    "  })\n",
    "  submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "  print(\"✅ submission.csv 저장 완료:\", submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "id": "a89c2fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>Training loss</td><td>█▄▄▄▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>▅▃▃▂▂▂▁▁▂▂▁▁▁▂▁▂▂▂▃▃▃▄▃▃▃▅▄▄▄▅▅▆▇▆▆▇█▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1327</td></tr><tr><td>Training loss</td><td>0.25323</td></tr><tr><td>Validation loss</td><td>0.64952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-16_15-58-48</strong> at: <a href='https://wandb.ai/launcher1423-/my_model_training/runs/7986dxny' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training/runs/7986dxny</a><br> View project at: <a href='https://wandb.ai/launcher1423-/my_model_training' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251016_155848-7986dxny\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\git\\link_dl\\_04_your_code\\wandb\\run-20251016_160018-zx1t8kc7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/launcher1423-/my_model_training/runs/zx1t8kc7' target=\"_blank\">2025-10-16_16-00-18</a></strong> to <a href='https://wandb.ai/launcher1423-/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/launcher1423-/my_model_training' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/launcher1423-/my_model_training/runs/zx1t8kc7' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training/runs/zx1t8kc7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, batch_size=16, epochs=10000)\n",
      "{'epochs': 10000, 'batch_size': 16, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20], 'early_stop_patience': 100, 'early_stop_delta': 0, 'validation_intervals': 100}\n",
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "713 178\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.6572, Validation loss 0.6834 | \n",
      "Epoch 200, Training loss 0.6542, Validation loss 0.6788 | \n",
      "Epoch 300, Training loss 0.6497, Validation loss 0.6743 | \n",
      "Epoch 400, Training loss 0.6424, Validation loss 0.6691 | \n",
      "Epoch 500, Training loss 0.6353, Validation loss 0.6622 | \n",
      "Epoch 600, Training loss 0.6268, Validation loss 0.6543V_loss decreased (0.65443 --> 0.65434). Saving model... | \n",
      "Epoch 700, Training loss 0.6188, Validation loss 0.6476V_loss decreased (0.64772 --> 0.64765). Saving model... | \n",
      "Epoch 800, Training loss 0.6099, Validation loss 0.6419V_loss decreased (0.64194 --> 0.64190). Saving model... | \n",
      "Epoch 900, Training loss 0.6052, Validation loss 0.6373V_loss decreased (0.63733 --> 0.63730). Saving model... | \n",
      "Epoch 1000, Training loss 0.5993, Validation loss 0.6335Early stopping counter: 2 out of 100 | \n",
      "Epoch 1100, Training loss 0.5969, Validation loss 0.6298V_loss decreased (0.62983 --> 0.62978). Saving model... | \n",
      "Epoch 1200, Training loss 0.5931, Validation loss 0.6270V_loss decreased (0.62697 --> 0.62696). Saving model... | \n",
      "Epoch 1300, Training loss 0.5902, Validation loss 0.6253V_loss decreased (0.62534 --> 0.62532). Saving model... | \n",
      "Epoch 1400, Training loss 0.5878, Validation loss 0.6243Early stopping counter: 6 out of 100 | \n",
      "Epoch 1500, Training loss 0.5883, Validation loss 0.6232Early stopping counter: 4 out of 100 | \n",
      "Epoch 1600, Training loss 0.5857, Validation loss 0.6220Early stopping counter: 3 out of 100 | \n",
      "Epoch 1700, Training loss 0.5866, Validation loss 0.6201V_loss decreased (0.62010 --> 0.62007). Saving model... | \n",
      "Epoch 1800, Training loss 0.5896, Validation loss 0.6183V_loss decreased (0.61837 --> 0.61830). Saving model... | \n",
      "Epoch 1900, Training loss 0.5835, Validation loss 0.6165V_loss decreased (0.61650 --> 0.61645). Saving model... | \n",
      "Epoch 2000, Training loss 0.5825, Validation loss 0.6154Early stopping counter: 6 out of 100 | \n",
      "Epoch 2100, Training loss 0.5812, Validation loss 0.6146Early stopping counter: 5 out of 100 | \n",
      "Epoch 2200, Training loss 0.5805, Validation loss 0.6135Early stopping counter: 3 out of 100 | \n",
      "Epoch 2300, Training loss 0.5782, Validation loss 0.6124Early stopping counter: 5 out of 100 | \n",
      "Epoch 2400, Training loss 0.5804, Validation loss 0.6112V_loss decreased (0.61125 --> 0.61124). Saving model... | \n",
      "Epoch 2500, Training loss 0.5776, Validation loss 0.6099Early stopping counter: 4 out of 100 | \n",
      "Epoch 2600, Training loss 0.5756, Validation loss 0.6088Early stopping counter: 3 out of 100 | \n",
      "Epoch 2700, Training loss 0.5757, Validation loss 0.6072V_loss decreased (0.60725 --> 0.60721). Saving model... | \n",
      "Epoch 2800, Training loss 0.5723, Validation loss 0.6058Early stopping counter: 2 out of 100 | \n",
      "Epoch 2900, Training loss 0.5724, Validation loss 0.6040Early stopping counter: 1 out of 100 | \n",
      "Epoch 3000, Training loss 0.5696, Validation loss 0.6021V_loss decreased (0.60210 --> 0.60207). Saving model... | \n",
      "Epoch 3100, Training loss 0.5677, Validation loss 0.5997Early stopping counter: 4 out of 100 | \n",
      "Epoch 3200, Training loss 0.5670, Validation loss 0.5970Early stopping counter: 1 out of 100 | \n",
      "Epoch 3300, Training loss 0.5621, Validation loss 0.5936V_loss decreased (0.59367 --> 0.59359). Saving model... | \n",
      "Epoch 3400, Training loss 0.5630, Validation loss 0.5894Early stopping counter: 6 out of 100 | \n",
      "Epoch 3500, Training loss 0.5607, Validation loss 0.5856Early stopping counter: 1 out of 100 | \n",
      "Epoch 3600, Training loss 0.5526, Validation loss 0.5803V_loss decreased (0.58058 --> 0.58031). Saving model... | \n",
      "Epoch 3700, Training loss 0.5496, Validation loss 0.5766Early stopping counter: 6 out of 100 | \n",
      "Epoch 3800, Training loss 0.5468, Validation loss 0.5727Early stopping counter: 12 out of 100 | \n",
      "Epoch 3900, Training loss 0.5421, Validation loss 0.5668V_loss decreased (0.56693 --> 0.56681). Saving model... | \n",
      "Epoch 4000, Training loss 0.5388, Validation loss 0.5623Early stopping counter: 11 out of 100 | \n",
      "Epoch 4100, Training loss 0.5341, Validation loss 0.5569V_loss decreased (0.55690 --> 0.55686). Saving model... | \n",
      "Epoch 4200, Training loss 0.5329, Validation loss 0.5559Early stopping counter: 5 out of 100 | \n",
      "Epoch 4300, Training loss 0.5228, Validation loss 0.5468Early stopping counter: 2 out of 100 | \n",
      "Epoch 4400, Training loss 0.5177, Validation loss 0.5402V_loss decreased (0.54042 --> 0.54016). Saving model... | \n",
      "Epoch 4500, Training loss 0.5147, Validation loss 0.5339V_loss decreased (0.53426 --> 0.53394). Saving model... | \n",
      "Epoch 4600, Training loss 0.5051, Validation loss 0.5301Early stopping counter: 2 out of 100 | \n",
      "Epoch 4700, Training loss 0.5019, Validation loss 0.5216Early stopping counter: 11 out of 100 | \n",
      "Epoch 4800, Training loss 0.4975, Validation loss 0.5179Early stopping counter: 1 out of 100 | \n",
      "Epoch 4900, Training loss 0.4914, Validation loss 0.5118Early stopping counter: 1 out of 100 | \n",
      "Epoch 5000, Training loss 0.4823, Validation loss 0.5216Early stopping counter: 13 out of 100 | \n",
      "Epoch 5100, Training loss 0.4800, Validation loss 0.5004Early stopping counter: 13 out of 100 | \n",
      "Epoch 5200, Training loss 0.4732, Validation loss 0.4972Early stopping counter: 1 out of 100 | \n",
      "Epoch 5300, Training loss 0.4706, Validation loss 0.4981Early stopping counter: 8 out of 100 | \n",
      "Epoch 5400, Training loss 0.4619, Validation loss 0.4992Early stopping counter: 10 out of 100 | \n",
      "Epoch 5500, Training loss 0.4605, Validation loss 0.5009Early stopping counter: 4 out of 100 | \n",
      "Epoch 5600, Training loss 0.4559, Validation loss 0.4859Early stopping counter: 8 out of 100 | \n",
      "Epoch 5700, Training loss 0.4526, Validation loss 0.4820Early stopping counter: 17 out of 100 | \n",
      "Epoch 5800, Training loss 0.4495, Validation loss 0.4689Early stopping counter: 2 out of 100 | \n",
      "Epoch 5900, Training loss 0.4459, Validation loss 0.4653Early stopping counter: 7 out of 100 | \n",
      "Epoch 6000, Training loss 0.4447, Validation loss 0.4663Early stopping counter: 3 out of 100 | \n",
      "Epoch 6100, Training loss 0.4406, Validation loss 0.4608V_loss decreased (0.46095 --> 0.46082). Saving model... | \n",
      "Epoch 6200, Training loss 0.4439, Validation loss 0.4618Early stopping counter: 15 out of 100 | \n",
      "Epoch 6300, Training loss 0.4355, Validation loss 0.4593Early stopping counter: 1 out of 100 | \n",
      "Epoch 6400, Training loss 0.4378, Validation loss 0.4625Early stopping counter: 9 out of 100 | \n",
      "Epoch 6500, Training loss 0.4369, Validation loss 0.4599Early stopping counter: 23 out of 100 | \n",
      "Epoch 6600, Training loss 0.4320, Validation loss 0.4549V_loss decreased (0.45494 --> 0.45490). Saving model... | \n",
      "Epoch 6700, Training loss 0.4270, Validation loss 0.4987Early stopping counter: 14 out of 100 | \n",
      "Epoch 6800, Training loss 0.4290, Validation loss 0.4650Early stopping counter: 7 out of 100 | \n",
      "Epoch 6900, Training loss 0.4304, Validation loss 0.4561Early stopping counter: 64 out of 100 | \n",
      "Epoch 7000, Training loss 0.4246, Validation loss 0.4530Early stopping counter: 6 out of 100 | \n",
      "Epoch 7100, Training loss 0.4249, Validation loss 0.4642Early stopping counter: 18 out of 100 | \n",
      "Epoch 7200, Training loss 0.4276, Validation loss 0.4579Early stopping counter: 50 out of 100 | \n",
      "Epoch 7300, Training loss 0.4248, Validation loss 0.4806Early stopping counter: 65 out of 100 | \n",
      "Epoch 7400, Training loss 0.4265, Validation loss 0.4521Early stopping counter: 98 out of 100 | \n",
      "Epoch 7500, Training loss 0.4196, Validation loss 0.4679Early stopping counter: 18 out of 100 | \n",
      "Epoch 7600, Training loss 0.4214, Validation loss 0.4510Early stopping counter: 33 out of 100 | \n",
      "Epoch 7700, Training loss 0.4155, Validation loss 0.4675Early stopping counter: 17 out of 100 | \n",
      "Epoch 7800, Training loss 0.4167, Validation loss 0.4568Early stopping counter: 47 out of 100 | \n",
      "Epoch 7900, Training loss 0.4124, Validation loss 0.4491Early stopping counter: 8 out of 100 | \n",
      "Epoch 8000, Training loss 0.4171, Validation loss 0.4603Early stopping counter: 2 out of 100 | \n",
      "Epoch 8100, Training loss 0.4178, Validation loss 0.4507Early stopping counter: 58 out of 100 | \n",
      "Epoch 8200, Training loss 0.4117, Validation loss 0.4892Early stopping counter: 23 out of 100 | \n",
      "Epoch 8300, Training loss 0.4093, Validation loss 0.4491Early stopping counter: 12 out of 100 | \n",
      "Epoch 8400, Training loss 0.4124, Validation loss 0.4709Early stopping counter: 59 out of 100 | \n",
      "Epoch 8500, Training loss 0.4081, Validation loss 0.4464Early stopping counter: 38 out of 100 | \n",
      "Epoch 8600, Training loss 0.4082, Validation loss 0.4677Early stopping counter: 43 out of 100 | \n",
      "Epoch 8700, Training loss 0.4065, Validation loss 0.4702Early stopping counter: 52 out of 100 | \n",
      "Epoch 8800, Training loss 0.4094, Validation loss 0.4637Early stopping counter: 47 out of 100 | \n",
      "Epoch 8900, Training loss 0.4075, Validation loss 0.4441V_loss decreased (0.44439 --> 0.44410). Saving model... | \n",
      "Epoch 9000, Training loss 0.4085, Validation loss 0.4563Early stopping counter: 4 out of 100 | \n",
      "Epoch 9100, Training loss 0.4037, Validation loss 0.4668Early stopping counter: 69 out of 100 | \n",
      "Epoch 9200, Training loss 0.3991, Validation loss 0.4443Early stopping counter: 20 out of 100 | \n",
      "Epoch 9300, Training loss 0.4001, Validation loss 0.4431Early stopping counter: 28 out of 100 | \n",
      "Epoch 9400, Training loss 0.4038, Validation loss 0.4488Early stopping counter: 20 out of 100 | \n",
      "Epoch 9500, Training loss 0.3969, Validation loss 0.4796Early stopping counter: 23 out of 100 | \n",
      "Epoch 9600, Training loss 0.3997, Validation loss 0.4490Early stopping counter: 28 out of 100 | \n",
      "Epoch 9700, Training loss 0.3993, Validation loss 0.4439Early stopping counter: 128 out of 100 *** TRAIN EARLY STOPPED! *** | \n",
      "Epoch 9800, Training loss 0.3997, Validation loss 0.4616Early stopping counter: 12 out of 100 | \n",
      "Epoch 9900, Training loss 0.4000, Validation loss 0.4480Early stopping counter: 112 out of 100 *** TRAIN EARLY STOPPED! *** | \n",
      "Epoch 10000, Training loss 0.3960, Validation loss 0.4647Early stopping counter: 75 out of 100 | \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>Training loss</td><td>██▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▄▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>██▇▇▇▆▆▆▆▆▅▅▅▅▅▄▃▃▂▂▁▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10000</td></tr><tr><td>Training loss</td><td>0.39603</td></tr><tr><td>Validation loss</td><td>0.4647</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-16_16-00-18</strong> at: <a href='https://wandb.ai/launcher1423-/my_model_training/runs/zx1t8kc7' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training/runs/zx1t8kc7</a><br> View project at: <a href='https://wandb.ai/launcher1423-/my_model_training' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251016_160018-zx1t8kc7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "✅ submission.csv 저장 완료:    PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n"
     ]
    }
   ],
   "source": [
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=True, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=16, help=\"Batch size (int, default: 512)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=10_000, help=\"Number of training epochs (int, default:1_000)\"\n",
    "  )\n",
    "\n",
    "  args = parser.parse_args(args=[])\n",
    "  \n",
    "  main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d9f2c",
   "metadata": {},
   "source": [
    "## [요구사항 1] titanic 딥러닝 모델 기본 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08491c",
   "metadata": {},
   "source": [
    "![](https://github.com/Minelauncher/LINK_DL-SAVE/blob/main/HW2/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89%20%EC%BA%90%EA%B8%80%20%EA%B2%B0%EA%B3%BC.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4e3a9",
   "metadata": {},
   "source": [
    "## [요구사항 2] Activation Function과 Batch Size변경 및 선택하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1ee8c",
   "metadata": {},
   "source": [
    "![](https://github.com/Minelauncher/LINK_DL-SAVE/blob/main/HW2/%ED%99%9C%EC%84%B1%ED%99%94%20%ED%95%A8%EC%88%98%20%EB%B9%84%EA%B5%90%20%EC%8B%9C%EB%93%9C%20%EA%B3%A0%EC%A0%95.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9edff6",
   "metadata": {},
   "source": [
    "캐글에 제출한 결과를 바탕으로 Sigmoid, ELU, LeakyReLU, ReLU중 Sigmoid가 가장 분류 성능이 좋았음을 알 수 있었다.\n",
    "\n",
    "하이퍼 파라미터는 1만 에포크를 기준으로 배치사이즈를 16으로 고정하여 시도하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e20c2",
   "metadata": {},
   "source": [
    "![](https://github.com/Minelauncher/LINK_DL-SAVE/blob/main/HW2/%EB%B0%B0%EC%B9%98%20%EC%82%AC%EC%9D%B4%EC%A6%88%20%EB%B9%84%EA%B5%90%20%EC%8B%9C%EB%93%9C%20%EA%B3%A0%EC%A0%95.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06d37d",
   "metadata": {},
   "source": [
    "캐글에 제출한 결과를 바탕으로 16, 32, 64, 128 배치 사이즈를 비교하였다. 배치 사이즈 16이 가장 성능이 좋았고 배치 사이즈가 커질 수록 정확도가 낮아짐을 확인 할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf86d33",
   "metadata": {},
   "source": [
    "## [요구사항 3] 테스트 및 submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "id": "fc7e6a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\git\\link_dl\\_04_your_code\\wandb\\run-20251016_160640-dmuob3u5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/launcher1423-/my_model_training/runs/dmuob3u5' target=\"_blank\">classic-fire-57</a></strong> to <a href='https://wandb.ai/launcher1423-/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/launcher1423-/my_model_training' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/launcher1423-/my_model_training/runs/dmuob3u5' target=\"_blank\">https://wandb.ai/launcher1423-/my_model_training/runs/dmuob3u5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "✅ latest_submission.csv 저장 완료:    PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "'n_hidden_unit_list': [20, 20],\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "mode=\"online\" if args.wandb else \"disabled\",\n",
    "project=\"my_model_training\",\n",
    "notes=\"My first wandb experiment\",\n",
    "tags=[\"my_model\", \"homework2\"],\n",
    "config=config\n",
    ")\n",
    "\n",
    "latest_model = MyModel(n_input=10, n_output=1)\n",
    "latest_model.eval() # 모델 평가 모드\n",
    "latest_file_path = os.path.join(CHECKPOINT_FILE_PATH, \"_checkpoint_latest.pt\")\n",
    "latest_model.load_state_dict(torch.load(latest_file_path, map_location=torch.device('cpu')))\n",
    "\n",
    "# --- test dataset 준비\n",
    "_, _, test_dataset = get_preprocessed_dataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "# --- 예측\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['input']\n",
    "        outputs = latest_model(inputs)\n",
    "        preds = (outputs >= 0.5).int()\n",
    "        preds = preds.ravel().int()\n",
    "\n",
    "# --- submission.csv 파일로 저장\n",
    "latest_submission = pd.DataFrame({\n",
    "    'PassengerId': range(892, 892 + len(preds)),  # Kaggle Titanic 기준 test.csv ID 시작 892\n",
    "    'Survived': preds\n",
    "})\n",
    "latest_submission.to_csv('latest_submission.csv', index=False)\n",
    "\n",
    "print(\"✅ latest_submission.csv 저장 완료:\", latest_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031a8eb",
   "metadata": {},
   "source": [
    "![](https://github.com/Minelauncher/LINK_DL-SAVE/blob/main/HW2/Early%20Stopping%20%EA%B2%80%EC%A6%9D.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9a97e",
   "metadata": {},
   "source": [
    "## [요구사항 4] submission.csv 제출 및 등수확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82544543",
   "metadata": {},
   "source": [
    "![](https://github.com/Minelauncher/LINK_DL-SAVE/blob/main/HW2/%EC%BA%90%EA%B8%80%20%EB%93%B1%EC%88%98.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a54a67",
   "metadata": {},
   "source": [
    "## 숙제 후기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932bed0",
   "metadata": {},
   "source": [
    "파이토치의 코드를 구경할 수 있어서 좋았다.\n",
    "\n",
    "하지만 경로 문제가 너무 걸렸고 주피터 노트북과 같은 형태로 제출하는 것이 힘들다. 기존 코드를 수정해야 했기 때문이다.\n",
    "\n",
    "코드 전처리 부분에서는 판다스 문법을 다 까먹어서 이해가 어려웠다.\n",
    "\n",
    "Adam 옵티마이저를 쓰면 조금은 그래프가 깔끔해졌다.\n",
    "\n",
    "WanDB같은 좋은 시각화 사이트가 있다는 것을 처음 알았다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "link_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
